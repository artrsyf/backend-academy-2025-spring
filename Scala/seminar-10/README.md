# Работа с Kafka. Продолжение

## Producer и Backpreasure

Продюсеры публикуют события в топики Kafka, откуда они потребляются одним или несколькими консьюмерами. Когда продюсер отправляет данные со скоростью, превышающей ту, которую кластер или консьюмеры Kafka могут обработать, это может привести к ошибкам и сбоям.

Чтобы недопустить сбоя, нужно настроить параметры продюсера, определяющие, как он будет вести себя при высокой нагрузке:

* max.block.ms - максимальное время, которое продюсер ждет перед следующей отправкой;
* buffer.memory - размер буффер, который копится для отправки;
* retries - количество ретраев на отправку.

## Consumer и Backpreasure

Backpressure на стороне консьюмера появляется, когда консьюмер не способен обрабатывать сообщения так же быстро, как они продюсятся в топик. Здесь так же потребуется правильная настройка конфигурации:

* max.poll.records

Так же потребуется правильная реализации консьюмер-логики в приложении:

* Правильный коммит оффсетов (автоматический или ручной)
* Правильный backoff period (например, настроить его экспоненциальным, вместо фиксированного)

Что может предложить FS2 Kafka для организации backpreasure можно найти в документации на странице [Technical Details](https://fd4s.github.io/fs2-kafka/docs/technical-details#consumer-streaming).

## Autocommit

Как вы уже знаете, консьюмеры сами, раз в определенное количество секунд отправляют запрос на сервер для получения новых данных. И, как вы уже знаете, cуществуют консьюмер-группы, в которые объединяются эти самые консьюмеры, для каждой группы существует собственный оффсет относительно каждой партиции каждого топика.

На прошлом семинаре мы рассмотрели способ выставления оффсета (это называется коммит оффсета) с помощью параметра *enable.auto.commit*.

Автокоммит ставится на принятый консьюмером батч, независимо от успешности его обработки в приложении. Автокоммит происходит по интервальному параметру *auto.commit.interval.ms*.

Так, например, если *auto.commit.interval.ms=6000*, а *max.poll.inverval.ms=3000*, то оффсет будет сохраняться не реже, чем на каждый второй батч.

## Manual commit

Какие проблемы могут возникнуть с autocommit?

Допустим, мы заполлили первые 100 сообщений в партиции, произошел автокоммит, но консьюмер обработал только 60 в момент, когда приложение засбоило и перезапустилось. Тогда новый консьюмер начнет получать сообщения с 101 оффсета, что приведёт к потере сообщений между 61 и 101 оффсетами.

Чтобы гарантировать at-least-once delivery нам потребуется самим выставлять оффсет только в случае успешности обработки сообщения в нашем приложении-консьюмере.

Что может предложить FS2 Kafka для реализации manual commit можно найти в документации на странице Consumers в разделе [Offsets Commits](https://fd4s.github.io/fs2-kafka/docs/consumers#offset-commits).
